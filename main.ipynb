{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths and labels\n",
    "def load_data(image_dir, label_file):\n",
    "    data = []\n",
    "    labels = pd.read_csv(label_file)\n",
    "    \n",
    "    for index, row in labels.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['FILENAME'])\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img = cv2.resize(img, (128, 32))  # Resize to a fixed size\n",
    "        img = img_to_array(img)\n",
    "        data.append(img)\n",
    "    \n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    return data, labels['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Developments\\\\Python\\\\OCR Implementation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load train, validation, and test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_images, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/train_v2/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/CSV/written_name_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(image_dir, label_file)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m labels\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      7\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFILENAME\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m32\u001b[39m))  \u001b[38;5;66;03m# Resize to a fixed size\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load train, validation, and test data\n",
    "train_images, train_labels = load_data('dataset/train_v2/train', 'dataset/CSV/written_name_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels = load_data('dataset/validation_v2', 'dataset/CSV/written_name_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_data('dataset/test_v2', 'dataset/CSV/written_name_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_images, val_labels = load_data('dataset/validation_v2', 'dataset/CSV/validation_labels.csv')\n",
    "test_images, test_labels = load_data('dataset/test_v2', 'dataset/CSV/test_labels.csv')\n",
    "\n",
    "# Convert labels to categorical (for a simple OCR problem; this might change depending on your actual labels)\n",
    "char_list = 'abcdefghijklmnopqrstuvwxyz0123456789'\n",
    "char_to_num = {char: i for i, char in enumerate(char_list)}\n",
    "num_to_char = {i: char for i, char in enumerate(char_list)}\n",
    "\n",
    "def encode_labels(labels):\n",
    "    encoded = []\n",
    "    for label in labels:\n",
    "        encoded.append([char_to_num[char] for char in label])\n",
    "    return np.array(encoded)\n",
    "\n",
    "train_labels_encoded = encode_labels(train_labels)\n",
    "val_labels_encoded = encode_labels(val_labels)\n",
    "test_labels_encoded = encode_labels(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: opencv-python in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pandas in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (3.9.1)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: setuptools in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: packaging in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: namex in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: optree in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\developments\\python\\ocr implementation\\ocr\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python pandas matplotlib joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "    img = cv2.resize(img, (128, 32))  # Resize to a fixed size\n",
    "    img = img_to_array(img) / 255.0  # Normalize\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths and labels with parallel processing\n",
    "def load_data(image_dir, label_file):\n",
    "    labels = pd.read_csv(label_file)\n",
    "    labels['IDENTITY'] = labels['IDENTITY'].astype(str)\n",
    "    image_paths = [os.path.join(image_dir, row['FILENAME']) for index, row in labels.iterrows()]\n",
    "    \n",
    "    # Use parallel processing to preprocess images\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    data = Parallel(n_jobs=num_cores)(delayed(preprocess_image)(image_path) for image_path in image_paths)\n",
    "    \n",
    "    data = np.array(data, dtype=\"float\")\n",
    "    return data, labels['IDENTITY'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train, validation, and test data\n",
    "train_images, train_labels = load_data('dataset/train_v2/train', 'dataset/CSV/written_name_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels = load_data('dataset/validation_v2/validation', 'dataset/CSV/written_name_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = load_data('dataset/test_v2/test', 'dataset/CSV/written_name_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical (for a simple OCR problem; this might change depending on your actual labels)\n",
    "import string\n",
    "\n",
    "# Combine all characters into one variable\n",
    "char_list = string.ascii_lowercase + string.ascii_uppercase + string.digits + string.punctuation +' '\n",
    "# char_list = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 -~`!@#$%^&*()_+=[]{}|;:,.<>?/'\n",
    "char_to_num = {char: i for i, char in enumerate(char_list)}\n",
    "num_to_char = {i: char for i, char in enumerate(char_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_labels(labels):\n",
    "    encoded = []\n",
    "    for label in labels:\n",
    "        try:\n",
    "            encoded.append([char_to_num[char] for char in label])\n",
    "        except KeyError:\n",
    "            # Handle any invalid characters\n",
    "            encoded.append([char_to_num[char] for char in label if char in char_to_num])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_encoded = encode_labels(train_labels)\n",
    "val_labels_encoded = encode_labels(val_labels)\n",
    "test_labels_encoded = encode_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform length\n",
    "max_length = max(max(len(label) for label in train_labels_encoded),\n",
    "                 max(len(label) for label in val_labels_encoded),\n",
    "                 max(len(label) for label in test_labels_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_padded = pad_sequences(train_labels_encoded, maxlen=max_length, padding='post')\n",
    "val_labels_padded = pad_sequences(val_labels_encoded, maxlen=max_length, padding='post')\n",
    "test_labels_padded = pad_sequences(test_labels_encoded, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input_shape = (32, 128, 1)  # (height, width, channels)\n",
    "input_shape = test_images.shape[1:]\n",
    "inputs = Input(shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The total size of the tensor must be unchanged. Received: input_shape=(4, 128, 128), target_shape=(16, 8192)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 41\u001b[0m\n\u001b[0;32m     36\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model(inputs, dense)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 41\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[155], line 27\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(input_shape, char_list)\u001b[0m\n\u001b[0;32m     24\u001b[0m pool_3 \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))(activation_3)  \u001b[38;5;66;03m# Adjusted pooling size to reduce downsampling\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Reshape for RNN layers\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# RNN layers\u001b[39;00m\n\u001b[0;32m     30\u001b[0m rnn_1 \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(reshaped)\n",
      "File \u001b[1;32md:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\operation_utils.py:302\u001b[0m, in \u001b[0;36mcompute_reshape_output_shape\u001b[1;34m(input_shape, newshape, newshape_arg_name)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unknown_dim_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;241m!=\u001b[39m math\u001b[38;5;241m.\u001b[39mprod(newshape):\n\u001b[1;32m--> 302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe total size of the tensor must be unchanged. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape_arg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m         )\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m newshape\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# We have one -1 in `newshape`, compute the actual value\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: The total size of the tensor must be unchanged. Received: input_shape=(4, 128, 128), target_shape=(16, 8192)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Dense, LSTM, Bidirectional, TimeDistributed, Lambda, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(input_shape, char_list):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers with Batch Normalization and Activation\n",
    "    conv_1 = Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    batch_norm_1 = BatchNormalization()(conv_1)\n",
    "    activation_1 = Activation('relu')(batch_norm_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(2, 1))(activation_1)  # Adjusted pooling size to reduce downsampling\n",
    "\n",
    "    conv_2 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "    batch_norm_2 = BatchNormalization()(conv_2)\n",
    "    activation_2 = Activation('relu')(batch_norm_2)\n",
    "    pool_2 = MaxPooling2D(pool_size=(2, 1))(activation_2)  # Adjusted pooling size to reduce downsampling\n",
    "\n",
    "    conv_3 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "    batch_norm_3 = BatchNormalization()(conv_3)\n",
    "    activation_3 = Activation('relu')(batch_norm_3)\n",
    "    pool_3 = MaxPooling2D(pool_size=(2, 1))(activation_3)  # Adjusted pooling size to reduce downsampling\n",
    "\n",
    "    # Reshape for RNN layers\n",
    "    reshaped = Reshape(target_shape=((32 // 2), (128 // 2) * 128))(pool_3)\n",
    "\n",
    "    # RNN layers\n",
    "    rnn_1 = Bidirectional(LSTM(128, return_sequences=True))(reshaped)\n",
    "    rnn_2 = Bidirectional(LSTM(128, return_sequences=True))(rnn_1)\n",
    "\n",
    "    dense = TimeDistributed(Dense(len(char_list) + 1, activation='softmax'))(rnn_2)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs, dense)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = build_model((32, 128, 1), char_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate input length\n",
    "# Calculate input length for the CTC loss function\n",
    "# Calculate input length for the CTC loss function\n",
    "input_length_train = np.ones((len(train_images), 1)) * (32 // 2)  # Adjusted to ensure sufficient length\n",
    "input_length_val = np.ones((len(val_images), 1)) * (32 // 2)      # Adjusted to ensure sufficient length\n",
    "input_length_test = np.ones((len(test_images), 1)) * (32 // 2)    # Adjusted to ensure sufficient length\n",
    "\n",
    "\n",
    "label_length_train = np.ones((len(train_images), 1)) * max_length\n",
    "label_length_val = np.ones((len(val_images), 1)) * max_length\n",
    "label_length_test = np.ones((len(test_images), 1)) * max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CTC Loss\n",
    "# labels = Input(name='the_labels', shape=[max_length], dtype='float32')\n",
    "# input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "# label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "# ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([dense, labels, input_length, label_length])\n",
    "\n",
    "# CTC Loss\n",
    "labels = Input(name='the_labels', shape=[max_length], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([model.output, labels, input_length, label_length])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model to be used at training time\n",
    "model_train = Model(inputs=[model.input, labels, input_length, label_length], outputs=ctc_loss)\n",
    "model_train.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330961, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (330961, 32, 128, 1)\n",
      "Train labels padded shape: (330961, 34)\n",
      "Input length train shape: (330961, 1)\n",
      "Label length train shape: (330961, 1)\n",
      "Validation images shape: (41370, 32, 128, 1)\n",
      "Validation labels padded shape: (41370, 34)\n",
      "Input length val shape: (41370, 1)\n",
      "Label length val shape: (41370, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels padded shape:\", train_labels_padded.shape)\n",
    "print(\"Input length train shape:\", input_length_train.shape)\n",
    "print(\"Label length train shape:\", label_length_train.shape)\n",
    "\n",
    "print(\"Validation images shape:\", val_images.shape)\n",
    "print(\"Validation labels padded shape:\", val_labels_padded.shape)\n",
    "print(\"Input length val shape:\", input_length_val.shape)\n",
    "print(\"Label length val shape:\", label_length_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_22_1/ctc_1/CTCLoss defined at (most recent call last):\n  File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Lakshitha\\AppData\\Local\\Temp\\ipykernel_41692\\3767926917.py\", line 1, in <module>\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 318, in fit\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 882, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 556, in call\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 882, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 120, in call\n\n  File \"C:\\Users\\Lakshitha\\AppData\\Local\\Temp\\ipykernel_41692\\2972813071.py\", line 9, in ctc_lambda_func\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\legacy\\backend.py\", line 666, in ctc_batch_cost\n\nsequence_length(0) <= 4\n\t [[{{node functional_22_1/ctc_1/CTCLoss}}]] [Op:__inference_one_step_on_iterator_35704]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_length_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_length_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_length_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_22_1/ctc_1/CTCLoss defined at (most recent call last):\n  File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\Lakshitha\\AppData\\Local\\Temp\\ipykernel_41692\\3767926917.py\", line 1, in <module>\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 318, in fit\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 108, in one_step_on_data\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 51, in train_step\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 882, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 175, in call\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 556, in call\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 882, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 120, in call\n\n  File \"C:\\Users\\Lakshitha\\AppData\\Local\\Temp\\ipykernel_41692\\2972813071.py\", line 9, in ctc_lambda_func\n\n  File \"d:\\Developments\\Python\\OCR Implementation\\ocr\\lib\\site-packages\\keras\\src\\legacy\\backend.py\", line 666, in ctc_batch_cost\n\nsequence_length(0) <= 4\n\t [[{{node functional_22_1/ctc_1/CTCLoss}}]] [Op:__inference_one_step_on_iterator_35704]"
     ]
    }
   ],
   "source": [
    "model_train.fit(\n",
    "    x=[train_images, train_labels_padded, input_length_train, label_length_train],\n",
    "    y=np.zeros(len(train_images)),\n",
    "    validation_data=([val_images, val_labels_padded, input_length_val, label_length_val], np.zeros(len(val_images))),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output as cls\n",
    "\n",
    "# Data\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow.data as tfd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "IMG_WIDTH = 200\n",
    "IMG_HEIGHT = 50\n",
    "IMAGE_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# EPOCHS\n",
    "EPOCHS = 100\n",
    "\n",
    "# Model Name\n",
    "MODEL_NAME = 'Handwritten-OCR'\n",
    "\n",
    "# Learning Rate\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Random Seed\n",
    "np.random.seed(2569)\n",
    "tf.random.set_seed(2569)\n",
    "\n",
    "# File Paths\n",
    "train_csv_path = 'dataset/CSV/written_name_train.csv'\n",
    "valid_csv_path = 'dataset/CSV/written_name_validation.csv'\n",
    "test_csv_path = 'dataset/CSV/written_name_test.csv'\n",
    "\n",
    "train_image_dir = 'dataset/train_v2/train'\n",
    "valid_image_dir = 'dataset/validation_v2/validation'\n",
    "test_image_dir = 'dataset/test_v2/test'\n",
    "\n",
    "# Data Size\n",
    "TRAIN_SIZE = BATCH_SIZE * 10000\n",
    "VALID_SIZE = BATCH_SIZE * 5000\n",
    "TEST_SIZE  = BATCH_SIZE * 1000\n",
    "\n",
    "# AUTOTUNE\n",
    "AUTOTUNE = tfd.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CSV\n",
    "train_csv = pd.read_csv(train_csv_path)[:TRAIN_SIZE]\n",
    "\n",
    "# Validation CSV\n",
    "valid_csv = pd.read_csv(valid_csv_path)[:VALID_SIZE]\n",
    "\n",
    "# Test CSV\n",
    "test_csv = pd.read_csv(test_csv_path)[:TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [str(word) for word in train_csv['IDENTITY'].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
